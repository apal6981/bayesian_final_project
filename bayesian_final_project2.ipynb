{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"bayesian_final_project.ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1hyQoKJ20GiNwqjGBk53IRu95Hd3XvqZO\n",
    "\n",
    "My implementations\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from numba import njit,prange\n",
    "from functools import partial\n",
    "\n",
    "def multinomial_resampling(particles, weights):\n",
    "    \"\"\"\n",
    "    Resample particles based on their weights using multinomial resampling.\n",
    "    :param particles: An array of particles with shape (num_particles, particle_dimension).\n",
    "    :param weights: An array of weights with shape (num_particles,).\n",
    "    :return: The resampled particles.\n",
    "    \"\"\"\n",
    "    num_particles = particles.shape[0]\n",
    "\n",
    "    # Normalize the weights\n",
    "    # normalized_weights = weights / np.sum(weights)\n",
    "\n",
    "    # Resample particles using the multinomial distribution\n",
    "    resampled_indices = np.random.choice(num_particles, size=num_particles, p=weights)\n",
    "\n",
    "    # Select the resampled particles\n",
    "    resampled_particles = particles[resampled_indices]\n",
    "\n",
    "    return resampled_particles\n",
    "\n",
    "@njit(parallel=True)\n",
    "def multinomial_resampling_numba(weights):\n",
    "    N = len(weights)\n",
    "    indices = np.zeros(N, dtype=np.int32)\n",
    "    cumsum = np.cumsum(weights)\n",
    "    cumsum /= cumsum[-1]\n",
    "    random_nums = np.random.rand(N)\n",
    "    for i in prange(N):\n",
    "        indices[i] = np.searchsorted(cumsum, random_nums[i])\n",
    "    return indices\n",
    "\n",
    "# @njit(parallel=True)\n",
    "# def multinomial_resampling_numba(particles, weights):\n",
    "#     \"\"\"Perform multinomial resampling on the particles.\"\"\"\n",
    "#     num_particles = particles.shape[0]\n",
    "#     indices = np.zeros(num_particles, dtype=np.int64)\n",
    "#     cumsum_weights = np.cumsum(weights)\n",
    "#     cumsum_weights[-1] = 1.  # Ensure cumsum_weights[-1] = 1.0\n",
    "#     for i in range(num_particles):\n",
    "#         r = np.random.rand()\n",
    "#         j = 0\n",
    "#         while r > cumsum_weights[j]:\n",
    "#             j += 1\n",
    "#         indices[i] = j\n",
    "#     return particles[indices]\n",
    "\n",
    "import jax.numpy as jnp\n",
    "from jax import random, jit\n",
    "import jax\n",
    "\n",
    "def multinomial_resampling_jax(particles, weights, rng_key):\n",
    "    cumsum_weights = jnp.cumsum(weights)\n",
    "    cumsum_weights /= cumsum_weights[-1]\n",
    "\n",
    "    # Resample particles\n",
    "    u = random.uniform(rng_key, (particles.shape[0],))\n",
    "    indices = jnp.searchsorted(cumsum_weights, u)\n",
    "    # resampled_particles = particles[indices]\n",
    "\n",
    "    # Assign equal weights to each particle\n",
    "    # resampled_weights = jnp.ones(weights.shape) / weights.shape[0]\n",
    "\n",
    "    return indices\n",
    "\n",
    "@jit\n",
    "def multinomial_resampling_jit(particles, weights, rng_key):\n",
    "    cumsum_weights = jnp.cumsum(weights)\n",
    "    cumsum_weights /= cumsum_weights[-1]\n",
    "\n",
    "    # Resample particles\n",
    "    u = random.uniform(rng_key, (particles.shape[0],))\n",
    "    indices = jnp.searchsorted(cumsum_weights, u)\n",
    "    resampled_particles = particles[indices]\n",
    "\n",
    "    # Assign equal weights to each particle\n",
    "    # resampled_weights = jnp.ones(weights.shape) / weights.shape[0]\n",
    "\n",
    "    return resampled_particles\n",
    "\n",
    "# @jit\n",
    "# def searchsorted_jit(cumsum, x):\n",
    "#     # Find the indices where x would be inserted into cumsum\n",
    "#     # Assumes cumsum is sorted in ascending order\n",
    "#     return jnp.searchsorted(cumsum, x)\n",
    "\n",
    "# @jit\n",
    "# def multinomial_resampling_jit(particles, weights, rng):\n",
    "#     num_particles = particles.shape[0]\n",
    "\n",
    "#     # Calculate the cumulative sum of the weights\n",
    "#     cumsum = jnp.cumsum(weights)\n",
    "\n",
    "#     # # Normalize the weights\n",
    "#     # weights_norm = weights / jnp.sum(weights)\n",
    "\n",
    "#     # Resample the particles\n",
    "#     idxs = []\n",
    "#     for i in range(num_particles):\n",
    "#         # Draw a random number in [0,resample_particles_multinomial 1/num_particles)\n",
    "#         u = random.uniform(rng, shape=(1,)) / num_particles\n",
    "\n",
    "#         # Find the index of the first element in cumsum greater than u\n",
    "#         idx = searchsorted_jit(cumsum, u)\n",
    "\n",
    "#         # Append the index to the list\n",
    "#         idxs.append(idx)\n",
    "\n",
    "#         # Update the cumulative sum to account for the weight of the selected particle\n",
    "#         # cumsum = jax.ops.index_update(cumsum, idx, cumsum[idx] - weights[idx])\n",
    "#         cumsum = cumsum.at[idx].set(cumsum[idx] - weights[idx])\n",
    "\n",
    "#     # Convert the indices to an array\n",
    "#     idxs = jnp.array(idxs)\n",
    "\n",
    "#     # Use advanced indexing to select the resampled particles\n",
    "#     resampled_particles = particles[idxs]\n",
    "\n",
    "#     return resampled_particles\n",
    "\n",
    "# @partial(jit, static_argnums=(2,3))\n",
    "# def multinomial_resampling_jit(particles, weights, rng_key):\n",
    "#     cumsum_weights = jnp.cumsum(weights)\n",
    "#     cumsum_weights /= cumsum_weights[-1]\n",
    "\n",
    "#     # Resample particles\n",
    "#     u = random.uniform(rng_key, (particles.shape[0],))\n",
    "#     indices = jnp.searchsorted(cumsum_weights, u)\n",
    "#     # resampled_particles = particles[indices]\n",
    "\n",
    "#     # Assign equal weights to each particle\n",
    "#     # resampled_weights = jnp.ones(weights.shape) / weights.shape[0]\n",
    "\n",
    "#     return indices\n",
    "\n",
    "# def multinomial_resampling_jax(particles, weights, key):\n",
    "#     num_particles, particle_dimension = particles.shape\n",
    "\n",
    "#     # Normalize the weights\n",
    "#     # weights = weights / jnp.sum(weights)\n",
    "\n",
    "#     # Resample particles using the multinomial distribution\n",
    "#     key, subkey = random.split(key)\n",
    "#     resampled_indices = random.categorical(subkey, weights, shape=(num_particles,))\n",
    "#     resampled_particles = particles[resampled_indices]\n",
    "\n",
    "#     return resampled_particles\n",
    "\n",
    "\n",
    "# def multinomial_resampling_jax(particles, weights,rng_key):\n",
    "#     num_particles = particles.shape[0]\n",
    "\n",
    "#     # Compute cumulative sum of weights\n",
    "#     cumsum = jnp.cumsum(weights)\n",
    "\n",
    "#     # Sample indices using binary search\n",
    "#     indices = jax.lax.map(lambda key: searchsorted(cumsum, key), jax.random.split(rng_key, num=num_particles))\n",
    "\n",
    "#     # Resample particles based on indices\n",
    "#     resampled_particles = particles[indices]\n",
    "\n",
    "#     # Normalize weights\n",
    "#     # resampled_weights = jnp.full(num_particles, 1.0 / num_particles)\n",
    "\n",
    "#     return resampled_particles\n",
    "\n",
    "\n",
    "# def searchsorted(cumsum, key):\n",
    "#     lo = 0\n",
    "#     hi = cumsum.shape[0] - 1\n",
    "#     while lo < hi:\n",
    "#         mid = (lo + hi) // 2\n",
    "#         if cumsum[mid] < key:\n",
    "#             lo = mid + 1\n",
    "#         else:\n",
    "#             hi = mid\n",
    "#     return lo\n",
    "\n",
    "# def multinomial_resampling_jax(particresample_particles_multinomialles, weights,key):\n",
    "#     M = particles.shape[0]\n",
    "#     cum_weights = jnp.zeros(M+1)\n",
    "#     cumsum_fun = lambda c, w: (c + w, c + w)\n",
    "#     cum_weights = jax.lax.scan(cumsum_fun, cum_weights[:-1], weights)\n",
    "#     cum_weights = jnp.concatenate((jnp.array([0.0]), cum_weights[0]), axis=0)\n",
    "#     cum_weights = cum_weights[1:]\n",
    "#     cum_weights /= cum_weights[-1]\n",
    "#     uniform_samples = jax.random.uniform(key, (M,), dtype=jnp.float32)\n",
    "#     inds = jnp.searchsorted(cum_weights, uniform_samples)\n",
    "#     return particles[inds], jnp.ones(M) / M\n",
    "\n",
    "# @jit\n",
    "# def multinomial_resampling_jit(particles, weights,key):\n",
    "#     M = particles.shape[0]\n",
    "#     cum_weights = jnp.zeros(M+1)\n",
    "#     cumsum_fun = lambda c, w: (c + w, c + w)\n",
    "#     cum_weights = jax.lax.scan(cumsum_fun, cum_weights[:-1], weights)\n",
    "#     cum_weights = jnp.concatenate((jnp.array([0.0]), cum_weights[0]), axis=0)\n",
    "#     cum_weights = cum_weights[1:]\n",
    "#     cum_weights /= cum_weights[-1]\n",
    "#     uniform_samples = jax.random.uniform(key, (M,), dtype=jnp.float32)\n",
    "#     inds = jnp.searchsorted(cum_weights, uniform_samples)\n",
    "#     return particles[inds], jnp.ones(M) / M\n",
    "\n",
    "# @jit\n",
    "# def multinomial_resampling_jit(particles, weights,rng_key):\n",
    "#     num_particles = particles.shape[0]\n",
    "\n",
    "#     # Compute cumulative sum of weights\n",
    "#     cumsum = jnp.cumsum(weights)\n",
    "\n",
    "#     # Sample indices using binary search\n",
    "#     indices = jax.lax.map(lambda key: searchsorted_jit(cumsum, key), jax.random.split(rng_key, num=num_particles))\n",
    "\n",
    "#     # Resample particles based on indices\n",
    "#     resampled_particles = particles[indices]\n",
    "\n",
    "#     # Normalize weights\n",
    "#     # resampled_weights = jnp.full(num_particles, 1.0 / num_particles)\n",
    "\n",
    "#     return resampled_particles\n",
    "\n",
    "# @jit\n",
    "# def searchsorted_jit(cumsum, key):\n",
    "#     lo = 0\n",
    "#     hi = cumsum.shape[0] - 1\n",
    "#     while lo < hi:\n",
    "#         mid = (lo + hi) // 2\n",
    "#         if cumsum[mid] < key:\n",
    "#             lo = mid + 1\n",
    "#         else:\n",
    "#             hi = mid\n",
    "#     return lo\n",
    "\n",
    "# @jit\n",
    "# def multinomial_resampling_jit(particles, weights, key):\n",
    "#     num_particles, particle_dimension = particles.shape\n",
    "\n",
    "#     # Normalize the weights\n",
    "#     # weights = weights / np.sum(weights)\n",
    "\n",
    "#     # Resample particles using the multinomial distribution\n",
    "#     key, subkey = random.split(key)\n",
    "#     resampled_indices = random.categorical(subkey, weights, shape=(num_particles,))\n",
    "#     resampled_particles = particles[resampled_indices]\n",
    "\n",
    "#     return resampled_particles\n",
    "\n",
    "def systematic_resampling(particles, weights):\n",
    "    num_particles = particles.shape[0]\n",
    "    step_size = 1.0 / num_particles\n",
    "    r = np.random.uniform(0, step_size)\n",
    "    cumulative_weights = np.cumsum(weights)\n",
    "\n",
    "    indices = np.zeros(num_particles, dtype=int)\n",
    "    i = 0\n",
    "    for m in range(num_particles):\n",
    "        while r > cumulative_weights[i]:\n",
    "            i += 1\n",
    "        indices[m] = i\n",
    "        r += step_size\n",
    "        if r >= 1.0:\n",
    "            r -= 1.0\n",
    "            i = 0\n",
    "\n",
    "    return particles[indices]\n",
    "\n",
    "@njit(parallel=True)\n",
    "def systematic_resampling_numba(particles, weights):\n",
    "    \"\"\"Perform systematic resampling on the particles.\"\"\"\n",
    "    num_particles = particles.shape[0]\n",
    "    indices = np.zeros(num_particles, dtype=np.int64)\n",
    "    cumsum_weights = np.cumsum(weights)\n",
    "    cumsum_weights[-1] = 1.  # Ensure cumsum_weights[-1] = 1.0\n",
    "    step = 1.0 / num_particles\n",
    "    u = np.random.rand() * step\n",
    "    i = 0\n",
    "    for j in range(num_particles):\n",
    "        while cumsum_weights[i] < u:\n",
    "            i += 1\n",
    "        indices[j] = i\n",
    "        u += step\n",
    "    return particles[indices]\n",
    "\n",
    "def systematic_resampling_jax(weights, key):\n",
    "    n = len(weights)\n",
    "    indices = jnp.arange(n)\n",
    "    cum_weights = jnp.cumsum(weights)\n",
    "    step = cum_weights[-1] / n\n",
    "    u = (jnp.arange(n) + jax.random.uniform(key, (n,))) * step\n",
    "    j = jnp.zeros((), dtype=jnp.int32)\n",
    "    def body_fn(i, j):\n",
    "        j = jax.lax.cond(cum_weights[j] < u[i],\n",
    "                         lambda _: j + 1,\n",
    "                         lambda _: j,\n",
    "                         operand=None)\n",
    "        return j, ()\n",
    "    _, j = jax.lax.scan(body_fn, j, jnp.arange(n))\n",
    "    # indices = jax.ops.index_update(indices, jnp.arange(n), indices[j])\n",
    "    indices = indices.at[jnp.arange(n)].set(indices[j])\n",
    "    return indices\n",
    "\n",
    "@jit\n",
    "def systematic_resampling_jit(weights, key):\n",
    "    n = len(weights)\n",
    "    indices = jnp.arange(n)\n",
    "    cum_weights = jnp.cumsum(weights)\n",
    "    step = cum_weights[-1] / n\n",
    "    u = (jnp.arange(n) + jax.random.uniform(key, (n,))) * step\n",
    "    j = jnp.zeros((), dtype=jnp.int32)\n",
    "    def body_fn(i, j):\n",
    "        j = jax.lax.cond(cum_weights[j] < u[i],\n",
    "                         lambda _: j + 1,\n",
    "                         lambda _: j,\n",
    "                         operand=None)\n",
    "        return j, ()\n",
    "    _, j = jax.lax.scan(body_fn, j, jnp.arange(n))\n",
    "    # indices = jax.ops.index_update(indices, jnp.arange(n), indices[j])\n",
    "    indices = indices.at[jnp.arange(n)].set(indices[j])\n",
    "    return indices\n",
    "\n",
    "# num_particles = 100000\n",
    "particle_dimension = 1\n",
    "# particles = np.random.randn(num_particles, particle_dimension)\n",
    "# weights = np.random.rand(num_particles)\n",
    "seed = 42\n",
    "key = random.PRNGKey(seed)\n",
    "import time\n",
    "\n",
    "particle_lst = [1,10,100,1000,10000,100000,1000000,10000000]\n",
    "# particle_lst = [1,10,1000,10000]\n",
    "multi_np_times = []\n",
    "multi_numba_times = []\n",
    "multi_jax_times = []\n",
    "multi_jax_jit_times = []\n",
    "\n",
    "sys_np_times = []\n",
    "sys_numba_times = []\n",
    "sys_jax_times = []\n",
    "sys_jax_jit_times = []\n",
    "\n",
    "num_iters = 10\n",
    "for n_part in particle_lst:\n",
    "    print(\"Number of particles:\", n_part)\n",
    "    particles = np.random.randn(n_part, particle_dimension)\n",
    "    weights = np.ones(n_part)/n_part\n",
    "    particles_jax = jnp.array(particles)\n",
    "    weights_jax = jnp.array(weights)\n",
    "\n",
    "    elapsed_time = 0\n",
    "    print(\"multi numpy\")\n",
    "    for i in range(num_iters):\n",
    "        start_time = time.time()\n",
    "        stuff = multinomial_resampling(particles,weights)\n",
    "        elapsed_time += time.time()-start_time\n",
    "    multi_np_times.append(elapsed_time/num_iters)\n",
    "    del stuff\n",
    "\n",
    "    elapsed_time=0\n",
    "    print(\"multi numba\")\n",
    "    stuff = multinomial_resampling_numba(weights)\n",
    "    for i in range(num_iters):\n",
    "        start_time = time.time()\n",
    "        stuff = multinomial_resampling_numba(weights)\n",
    "        particles[stuff]\n",
    "        elapsed_time += time.time()-start_time\n",
    "    multi_numba_times.append(elapsed_time/num_iters)\n",
    "    del stuff\n",
    "\n",
    "    print(\"multi jax\")\n",
    "    elapsed_time=0\n",
    "    for i in range(num_iters):\n",
    "        start_time = time.time()\n",
    "        stuff = (multinomial_resampling_jax(particles_jax,weights_jax,key)).block_until_ready()\n",
    "        elapsed_time += time.time()-start_time\n",
    "    multi_jax_times.append(elapsed_time/num_iters)\n",
    "    del stuff\n",
    "\n",
    "    print(\"multi jax jit\")\n",
    "    elapsed_time = 0\n",
    "    multinomial_resampling_jit(particles_jax,weights_jax,key).block_until_ready()\n",
    "    for i in range(num_iters):\n",
    "        start_time = time.time()\n",
    "        stuff = multinomial_resampling_jit(particles_jax,weights_jax,key).block_until_ready()\n",
    "        elapsed_time += time.time()-start_time\n",
    "    multi_jax_jit_times.append(elapsed_time/num_iters)\n",
    "    del stuff\n",
    "\n",
    "    print(\"sys numpy\")\n",
    "    elapsed_time = 0\n",
    "    for i in range(num_iters):\n",
    "        start_time = time.time()\n",
    "        stuff = systematic_resampling(particles,weights)\n",
    "        elapsed_time += time.time()-start_time\n",
    "    sys_np_times.append(elapsed_time/num_iters)\n",
    "    del stuff\n",
    "\n",
    "    print(\"sys numba\")\n",
    "    elapsed_time = 0\n",
    "    stuff = systematic_resampling_numba(particles,weights)\n",
    "    for i in range(num_iters):\n",
    "        start_time = time.time()\n",
    "        stuff = systematic_resampling_numba(particles,weights)\n",
    "        elapsed_time += time.time()-start_time\n",
    "    sys_numba_times.append(elapsed_time/num_iters)\n",
    "    del stuff\n",
    "\n",
    "    print(\"sys jax\")\n",
    "    elapsed_time = 0\n",
    "    for i in range(num_iters):\n",
    "        start_time = time.time()\n",
    "        stuff = systematic_resampling_jax(weights_jax,key).block_until_ready()\n",
    "        particles_jax[stuff]\n",
    "        elapsed_time += time.time()-start_time\n",
    "    sys_jax_times.append(elapsed_time/num_iters)\n",
    "    del stuff\n",
    "\n",
    "    print(\"sys jax jit\")\n",
    "    elapsed_time = 0\n",
    "    systematic_resampling_jit(weights_jax,key).block_until_ready()\n",
    "    for i in range(num_iters):\n",
    "        start_time = time.time()\n",
    "        stuff = systematic_resampling_jit(weights_jax,key).block_until_ready()\n",
    "        particles_jax[stuff]\n",
    "        elapsed_time += time.time()-start_time\n",
    "    sys_jax_jit_times.append(elapsed_time/num_iters)\n",
    "    del stuff\n",
    "\n",
    "    del particles \n",
    "    del weights \n",
    "    del particles_jax\n",
    "    del weights_jax\n",
    "\n",
    "\"\"\"Create the plots\"\"\"\n",
    "\n",
    "print(multi_np_times)\n",
    "print(multi_numba_times)\n",
    "print(multi_jax_times)\n",
    "print(multi_jax_jit_times)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "multi_cpp = np.genfromtxt(\"execution_times_multinomial.csv\",delimiter=',')\n",
    "sys_cpp = np.genfromtxt(\"execution_times_systematic.csv\",delimiter=\",\")\n",
    "print(multi_cpp[:,1])\n",
    "\n",
    "fig, ax = plt.subplots(2,1,figsize=(4,12))\n",
    "# plt.figure()\n",
    "ax[0].plot(particle_lst,multi_np_times,label=\"numpy\")\n",
    "ax[0].plot(particle_lst,multi_numba_times,label=\"numba\")\n",
    "ax[0].plot(particle_lst,multi_jax_times,label=\"JAX\")\n",
    "ax[0].plot(particle_lst,multi_jax_jit_times,label=\"JAX JIT\")\n",
    "ax[0].plot(multi_cpp[:,0],multi_cpp[:,1],label=\"C++\")\n",
    "ax[0].semilogy()\n",
    "ax[0].semilogx()\n",
    "ax[0].set_xlabel(\"Number of particles\")\n",
    "ax[0].set_ylabel(\"Execution time (s)\")\n",
    "ax[0].legend()\n",
    "ax[0].set_title(\"Multinomial Resampling\")\n",
    "# plt.tight_layout()\n",
    "\n",
    "# plt.figure()\n",
    "ax[1].plot(particle_lst,sys_np_times,label=\"numpy\")\n",
    "ax[1].plot(particle_lst,sys_numba_times,label=\"numba\")\n",
    "ax[1].plot(particle_lst,sys_jax_times,label=\"JAX\")\n",
    "ax[1].plot(particle_lst,sys_jax_jit_times,label=\"JAX JIT\")\n",
    "ax[1].plot(sys_cpp[:,0],sys_cpp[:,1],label=\"C++\")\n",
    "ax[1].semilogy()\n",
    "ax[1].semilogx()\n",
    "ax[1].set_xlabel(\"Number of particles\")\n",
    "ax[1].set_ylabel(\"Execution time (s)\")\n",
    "ax[1].legend()\n",
    "ax[1].set_title(\"Systematic Resampling\")\n",
    "# ax[1].tight_layout()\n",
    "plt.tight_layout()\n",
    "# plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
